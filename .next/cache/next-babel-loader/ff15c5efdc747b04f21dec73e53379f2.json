{"ast":null,"code":"var _jsxFileName = \"E:\\\\Signify-master\\\\pages\\\\about.js\";\nimport React from \"react\";\nvar __jsx = React.createElement;\n\nconst Page = () => {\n  return __jsx(\"div\", {\n    style: {\n      marginTop: '2em'\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 3,\n      columnNumber: 5\n    }\n  }, __jsx(\"div\", {\n    className: \"jumbotron text-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 4,\n      columnNumber: 7\n    }\n  }, __jsx(\"h1\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 5,\n      columnNumber: 9\n    }\n  }, \"Voicify - ASL Translator\"), __jsx(\"h4\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 6,\n      columnNumber: 9\n    }\n  }, \"Voicify uses machine learning to transform webcam input into readable sign language using a variety of different techniques. The series of texts below detail the steps taken for signify to translate an image into a final word.\")), __jsx(\"div\", {\n    className: \"bg-secondary jumbotron\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 13,\n      columnNumber: 7\n    }\n  }, __jsx(\"h3\", {\n    className: \"text-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 14,\n      columnNumber: 9\n    }\n  }, \"1. OpenCV Pipeline\"), __jsx(\"div\", {\n    className: \"row justify-content-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 15,\n      columnNumber: 9\n    }\n  }, __jsx(\"img\", {\n    src: \"opencv.png\",\n    alt: \"OpenCV Pipeline Demo\",\n    className: \"img-responsive col-xs-12 col-md-6\",\n    style: {\n      height: '100%'\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 16,\n      columnNumber: 11\n    }\n  }), __jsx(\"div\", {\n    className: \"col-xs-12 col-md-6\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 22,\n      columnNumber: 11\n    }\n  }, __jsx(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 13\n    }\n  }, \"The first step of the process to transform an image to a letter output is our OpenCV pipeline. This pipeline is written as the following:\", __jsx(\"br\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 27,\n      columnNumber: 15\n    }\n  }), __jsx(\"code\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 28,\n      columnNumber: 15\n    }\n  }, \"cv.cvtColor(img, result, cv.COLOR_BGR2GRAY);\", __jsx(\"br\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 17\n    }\n  }), \"cv.adaptiveThreshold( result, result, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 21, 2 );\", __jsx(\"br\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 33,\n      columnNumber: 17\n    }\n  }), \"cv.cvtColor(result, result, cv.COLOR_GRAY2RGB);\"), __jsx(\"br\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 36,\n      columnNumber: 15\n    }\n  }), \"The above pipeline simply performs an adaptive threshold on a grayscaled version on the image, highlighting its edges which make the image easier to process through the next step, the tensorflow model.\")))), __jsx(\"div\", {\n    className: \"bg-secondary jumbotron\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 45,\n      columnNumber: 7\n    }\n  }, __jsx(\"h3\", {\n    className: \"text-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 46,\n      columnNumber: 9\n    }\n  }, \"2. Tensorflow CNN\"), __jsx(\"div\", {\n    className: \"row justify-content-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 47,\n      columnNumber: 9\n    }\n  }, __jsx(\"img\", {\n    src: \"model-architecture.png\",\n    alt: \"OpenCV Pipeline Demo\",\n    className: \"img-responsive col-xs-12 col-md-6\",\n    style: {\n      height: '100%'\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 48,\n      columnNumber: 11\n    }\n  }), __jsx(\"div\", {\n    className: \"col-xs-12 col-md-6\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 54,\n      columnNumber: 11\n    }\n  }, __jsx(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 55,\n      columnNumber: 13\n    }\n  }, \"After experimenting with various different model architectures, transfer learning from various different base convolutional neural network including vgg19, alexnet, and more, we settled on the architecture shown here, which both allowed the model to be run in real time as well as be fairly accurate. We took the output of a pre-trained convolutional neural network (mobile net) and added three dense layers to alter the output to classify hand signs.\")))), __jsx(\"div\", {\n    className: \"bg-secondary jumbotron\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 67,\n      columnNumber: 7\n    }\n  }, __jsx(\"h3\", {\n    className: \"text-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 9\n    }\n  }, \"3. Interpreting The Results\"), __jsx(\"div\", {\n    className: \"row justify-content-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 69,\n      columnNumber: 9\n    }\n  }, __jsx(\"img\", {\n    src: \"interpretation.png\",\n    alt: \"OpenCV Pipeline Demo\",\n    className: \"img-responsive col-xs-12 col-md-6\",\n    style: {\n      height: '100%'\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 70,\n      columnNumber: 11\n    }\n  }), __jsx(\"div\", {\n    className: \"col-xs-12 col-md-6\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 76,\n      columnNumber: 11\n    }\n  }, __jsx(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 77,\n      columnNumber: 13\n    }\n  }, \"The Tensorflow CNN mentioned above only gave us a stream of outputs, which had to be translated into a readable english word / set of letters, as shown in the image. To accomplish this, we developed a small algorithm like the following: If the previous detected letter is different from the current detector letter, and the previous detected letter has been repeated at least x number of times, then add the previous letter to the running predicted word. However, the threshold x may change from letter to letter, and we had to experiment with different values of x: smaller values for letters which the model had trouble with, and larger values for letters which the model was more confident with. Then, when a space character is detected, we run autocorrection and text to speech as mentioned in the text below.\")))), __jsx(\"div\", {\n    className: \"bg-secondary jumbotron\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 95,\n      columnNumber: 7\n    }\n  }, __jsx(\"h3\", {\n    className: \"text-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 96,\n      columnNumber: 9\n    }\n  }, \"4. Autocorrection And Text To Speech\"), __jsx(\"div\", {\n    className: \"row justify-content-center\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 97,\n      columnNumber: 9\n    }\n  }, __jsx(\"img\", {\n    src: \"tts.jpeg\",\n    alt: \"OpenCV Pipeline Demo\",\n    className: \"img-responsive col-xs-12 col-md-6\",\n    style: {\n      height: '100%'\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 98,\n      columnNumber: 11\n    }\n  }), __jsx(\"div\", {\n    className: \"col-xs-12 col-md-6\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 104,\n      columnNumber: 11\n    }\n  }, __jsx(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 105,\n      columnNumber: 13\n    }\n  }, \"However, the letters output by the previous step were not always 100% perfect, which is why we included autocorrection. For the select times where the previous steps are not able to accurately translate a word, we use simple autocorrection to change it to the nearest english word. Additionally, we used the browser text to speech API to speak out loud the predicted word, allowing for even more use cases.\")))));\n};\n\nexport default Page;","map":{"version":3,"sources":["E:/Signify-master/pages/about.js"],"names":["Page","marginTop","height"],"mappings":";;;;AAAA,MAAMA,IAAI,GAAG,MAAM;AACjB,SACE;AAAK,IAAA,KAAK,EAAE;AAAEC,MAAAA,SAAS,EAAE;AAAb,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAK,IAAA,SAAS,EAAC,uBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCADF,EAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0OAFF,CADF,EAUE;AAAK,IAAA,SAAS,EAAC,wBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAI,IAAA,SAAS,EAAC,aAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BADF,EAEE;AAAK,IAAA,SAAS,EAAC,4BAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AACE,IAAA,GAAG,EAAC,YADN;AAEE,IAAA,GAAG,EAAC,sBAFN;AAGE,IAAA,SAAS,EAAC,mCAHZ;AAIE,IAAA,KAAK,EAAE;AAAEC,MAAAA,MAAM,EAAE;AAAV,KAJT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,EAOE;AAAK,IAAA,SAAS,EAAC,oBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kJAIE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAJF,EAKE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qDAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAFF,0GAKE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IALF,oDALF,EAaE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAbF,8MADF,CAPF,CAFF,CAVF,EA0CE;AAAK,IAAA,SAAS,EAAC,wBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAI,IAAA,SAAS,EAAC,aAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBADF,EAEE;AAAK,IAAA,SAAS,EAAC,4BAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AACE,IAAA,GAAG,EAAC,wBADN;AAEE,IAAA,GAAG,EAAC,sBAFN;AAGE,IAAA,SAAS,EAAC,mCAHZ;AAIE,IAAA,KAAK,EAAE;AAAEA,MAAAA,MAAM,EAAE;AAAV,KAJT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,EAOE;AAAK,IAAA,SAAS,EAAC,oBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2cADF,CAPF,CAFF,CA1CF,EAgEE;AAAK,IAAA,SAAS,EAAC,wBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAI,IAAA,SAAS,EAAC,aAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCADF,EAEE;AAAK,IAAA,SAAS,EAAC,4BAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AACE,IAAA,GAAG,EAAC,oBADN;AAEE,IAAA,GAAG,EAAC,sBAFN;AAGE,IAAA,SAAS,EAAC,mCAHZ;AAIE,IAAA,KAAK,EAAE;AAAEA,MAAAA,MAAM,EAAE;AAAV,KAJT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,EAOE;AAAK,IAAA,SAAS,EAAC,oBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qzBADF,CAPF,CAFF,CAhEF,EA4FE;AAAK,IAAA,SAAS,EAAC,wBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAI,IAAA,SAAS,EAAC,aAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CADF,EAEE;AAAK,IAAA,SAAS,EAAC,4BAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AACE,IAAA,GAAG,EAAC,UADN;AAEE,IAAA,GAAG,EAAC,sBAFN;AAGE,IAAA,SAAS,EAAC,mCAHZ;AAIE,IAAA,KAAK,EAAE;AAAEA,MAAAA,MAAM,EAAE;AAAV,KAJT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,EAOE;AAAK,IAAA,SAAS,EAAC,oBAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8ZADF,CAPF,CAFF,CA5FF,CADF;AAqHD,CAtHD;;AAwHA,eAAeF,IAAf","sourcesContent":["const Page = () => {\n  return (\n    <div style={{ marginTop: '2em' }}>\n      <div className=\"jumbotron text-center\">\n        <h1>Voicify - ASL Translator</h1>\n        <h4>\n          Voicify uses machine learning to transform webcam input into readable\n          sign language using a variety of different techniques. The series of\n          texts below detail the steps taken for signify to translate an image\n          into a final word.\n        </h4>\n      </div>\n      <div className=\"bg-secondary jumbotron\">\n        <h3 className=\"text-center\">1. OpenCV Pipeline</h3>\n        <div className=\"row justify-content-center\">\n          <img\n            src=\"opencv.png\"\n            alt=\"OpenCV Pipeline Demo\"\n            className=\"img-responsive col-xs-12 col-md-6\"\n            style={{ height: '100%' }}\n          />\n          <div className=\"col-xs-12 col-md-6\">\n            <p>\n              The first step of the process to transform an image to a letter\n              output is our OpenCV pipeline. This pipeline is written as the\n              following:\n              <br />\n              <code>\n                cv.cvtColor(img, result, cv.COLOR_BGR2GRAY);\n                <br />\n                cv.adaptiveThreshold( result, result, 255,\n                cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 21, 2 );\n                <br />\n                cv.cvtColor(result, result, cv.COLOR_GRAY2RGB);\n              </code>\n              <br />\n              The above pipeline simply performs an adaptive threshold on a\n              grayscaled version on the image, highlighting its edges which make\n              the image easier to process through the next step, the tensorflow\n              model.\n            </p>\n          </div>\n        </div>\n      </div>\n      <div className=\"bg-secondary jumbotron\">\n        <h3 className=\"text-center\">2. Tensorflow CNN</h3>\n        <div className=\"row justify-content-center\">\n          <img\n            src=\"model-architecture.png\"\n            alt=\"OpenCV Pipeline Demo\"\n            className=\"img-responsive col-xs-12 col-md-6\"\n            style={{ height: '100%' }}\n          />\n          <div className=\"col-xs-12 col-md-6\">\n            <p>\n              After experimenting with various different model architectures,\n              transfer learning from various different base convolutional neural\n              network including vgg19, alexnet, and more, we settled on the\n              architecture shown here, which both allowed the model to be run in\n              real time as well as be fairly accurate. We took the output of a\n              pre-trained convolutional neural network (mobile net) and added\n              three dense layers to alter the output to classify hand signs.\n            </p>\n          </div>\n        </div>\n      </div>\n      <div className=\"bg-secondary jumbotron\">\n        <h3 className=\"text-center\">3. Interpreting The Results</h3>\n        <div className=\"row justify-content-center\">\n          <img\n            src=\"interpretation.png\"\n            alt=\"OpenCV Pipeline Demo\"\n            className=\"img-responsive col-xs-12 col-md-6\"\n            style={{ height: '100%' }}\n          />\n          <div className=\"col-xs-12 col-md-6\">\n            <p>\n              The Tensorflow CNN mentioned above only gave us a stream of\n              outputs, which had to be translated into a readable english word /\n              set of letters, as shown in the image. To accomplish this, we\n              developed a small algorithm like the following: If the previous\n              detected letter is different from the current detector letter, and\n              the previous detected letter has been repeated at least x number\n              of times, then add the previous letter to the running predicted\n              word. However, the threshold x may change from letter to letter,\n              and we had to experiment with different values of x: smaller\n              values for letters which the model had trouble with, and larger\n              values for letters which the model was more confident with. Then,\n              when a space character is detected, we run autocorrection and text\n              to speech as mentioned in the text below.\n            </p>\n          </div>\n        </div>\n      </div>\n      <div className=\"bg-secondary jumbotron\">\n        <h3 className=\"text-center\">4. Autocorrection And Text To Speech</h3>\n        <div className=\"row justify-content-center\">\n          <img\n            src=\"tts.jpeg\"\n            alt=\"OpenCV Pipeline Demo\"\n            className=\"img-responsive col-xs-12 col-md-6\"\n            style={{ height: '100%' }}\n          />\n          <div className=\"col-xs-12 col-md-6\">\n            <p>\n              However, the letters output by the previous step were not always\n              100% perfect, which is why we included autocorrection. For the\n              select times where the previous steps are not able to accurately\n              translate a word, we use simple autocorrection to change it to the\n              nearest english word. Additionally, we used the browser text to\n              speech API to speak out loud the predicted word, allowing for even\n              more use cases.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default Page;\n"]},"metadata":{},"sourceType":"module"}